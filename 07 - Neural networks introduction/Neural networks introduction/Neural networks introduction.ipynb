{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to (deep) neural networks\n",
    "\n",
    "<sup>This notebook is a part of Natural Language Processing class at the University of Ljubljana, Faculty for computer and information science. Please contact [slavko.zitnik@fri.uni-lj.si](mailto:slavko.zitnik@fri.uni-lj.si) for any comments.</sub>\n",
    "\n",
    "An artificial neural network is a network inspired by biological neural networks which are used to estimate or approximate functions that can depend on a large number of inputs. The notion *deep* comes from computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction.\n",
    "\n",
    "In this notebook we will use [Keras](https://keras.io/), which is a high-level API to train neural networks using different backends like [Tensorflow](https://github.com/tensorflow/tensorflow), [Theano](https://github.com/Theano/Theano) or [CNTK](https://github.com/Microsoft/cntk). \n",
    "\n",
    "For starters, we can check a simple Tensorflow's neural network visualization: [http://playground.tensorflow.org/](http://playground.tensorflow.org/).\n",
    "\n",
    "To install the basic requirements to work with Keras and Tensorflow, issue the following commands (for GPU-based installation, please see the [Tensorflow's documentation](https://www.tensorflow.org/install/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to neural networks\n",
    "\n",
    "A neural network (NN) is built from nodes (neurons) stacked in layers between the feature vector and the target vector. The simplest version of NN consists of one node - *perceptron*.\n",
    "\n",
    "The Perceptron is an algorithm for supervised learning of binary classifiers - functions that can decide whether an input (represented by a vector of numbers) belongs to one class or another. Much like logistic regression, the weights in a neural net are being multiplied by the input vertor summed up and feeded into the activation function's input.\n",
    "\n",
    "A Perceptron Network can be designed to have multiple layers, leading to the Multi-Layer Perceptron (MLP).\n",
    "\n",
    "<img src=\"imgs/single_layer.png\" width=\"65%\" />\n",
    "\n",
    "_(Source: Python Machine Learning, S. Raschka)_\n",
    "\n",
    "### Weights updating\n",
    "\n",
    "To find *the best* weights coefficients, we use an optimization algorithm (e.g. gradient descent). In every epoch we update the weight vector $w$ using the following update rule:\n",
    "\n",
    "$$\n",
    "w = w + \\Delta w, \\text{where } \\Delta w = - \\eta \\nabla J(w)\n",
    "$$\n",
    "\n",
    "To update the weights of the model, we update weights into the opposite direction (i.e. backward) of the gradient $ \\nabla J(w)$. \n",
    "\n",
    "In order to find the optimal weights of the model, we optimize an objective function (e.g. the sum of squared srrors) cost function $J(w)$. \n",
    "\n",
    "Furthermore, we multiply the gradient by a factor - the learning rate $\\eta$ , which we choose to balance the speed of learning against the risk of missing the global minimum of the cost function.\n",
    "\n",
    "### Activation function\n",
    "\n",
    "We define the activation function $\\phi(\\cdot)$ as follows:\n",
    "\n",
    "$$\n",
    "z = \\sum_{j} (w_j x_j + b_j) = \\mathbf{w}^T \\mathbf{x} + b\n",
    "$$\n",
    "\n",
    "$$\n",
    "a = \\phi(z)\n",
    "$$\n",
    "\n",
    "Examples of activation functions are $sigmoid$, $tanh$, $ReLu$, ...\n",
    "\n",
    "### Binary classification\n",
    "\n",
    "While we use the activation $\\phi(z)$ to compute the gradient update, we may use a threshold function _(Heaviside function)_ to squash the continuous-valued output into binary class labels for prediction:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\begin{cases}\n",
    "    1 & \\text{if } \\phi(z) \\geq 0 \\\\\n",
    "    0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "## Multi-layer neural networks architecture \n",
    "\n",
    "<img src=\"imgs/multi-layers-1.png\" width=\"50%\" />\n",
    "\n",
    "_(Source: Python Machine Learning, S. Raschka)_\n",
    "\n",
    "The figure shows the concept of an MLP consisting of three layers: one _input_ layer, one _hidden_ layer, and one _output_ layer. \n",
    "\n",
    "The units in the hidden layer are fully connected to the input layer, and the output layer is fully connected to the hidden layer, respectively. \n",
    "\n",
    "If such a network has **more than one hidden layer**, we also call it a **deep artificial neural network**.\n",
    "\n",
    "\n",
    "\n",
    "Further we use Keras with a selected backend, which already has implemented all the needed statistical methods we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Keras\n",
    "\n",
    "\n",
    "### The Otto Group dataset (Kaggle) preparation\n",
    "\n",
    ">The Otto Group is one of the world’s biggest e-commerce companies, A consistent analysis of the performance of products is crucial. However, due to diverse global infrastructure, many identical products get classified differently.\n",
    "For this competition, we have provided a dataset with 93 features for more than 200,000 products. The objective is to build a predictive model which is able to distinguish between our main product categories. \n",
    "Each row corresponds to a single product. There are a total of 93 numerical features, which represent counts of different events. All features have been obfuscated and will not be defined any further.\n",
    "\n",
    "https://www.kaggle.com/c/otto-group-product-classification-challenge/data (downloaded data in folder *data/kaggle_ottogroup/* folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 9 classes and 93 features.\n",
      "Label values: ['Class_1' 'Class_2' 'Class_3' 'Class_4' 'Class_5' 'Class_6' 'Class_7'\n",
      " 'Class_8' 'Class_9']\n",
      "\n",
      "First three labels: ['Class_6' 'Class_2' 'Class_3']\n",
      "Labels are one-hot encoded for training: \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n",
      "\n",
      "Training data: \n",
      "[[-0.2535081  -0.21010602 -0.30716544 ... -0.1295155  -0.3869381\n",
      "  -0.10496315]\n",
      " [ 0.40209323 -0.21010602 -0.30716544 ... -0.1295155  -0.3869381\n",
      "  -0.10496315]\n",
      " [ 1.0576946  -0.21010602 -0.30716544 ... -0.1295155  -0.3869381\n",
      "  -0.10496315]\n",
      " ...\n",
      " [-0.2535081   0.58857566 -0.30716544 ... -0.1295155  -0.3869381\n",
      "   0.72718406]\n",
      " [ 0.40209323 -0.21010602  0.03357394 ... -0.1295155  -0.3869381\n",
      "  -0.10496315]\n",
      " [-0.2535081  -0.21010602 -0.30716544 ... -0.1295155  -0.3869381\n",
      "  -0.10496315]]\n"
     ]
    }
   ],
   "source": [
    "from scripts.kaggle_data import load_data, preprocess_data, preprocess_labels\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train, labels = load_data('data/kaggle_ottogroup/train.csv', train=True)\n",
    "X_train, scaler = preprocess_data(X_train)\n",
    "Y_train, encoder = preprocess_labels(labels)\n",
    "\n",
    "X_test, ids = load_data('data/kaggle_ottogroup/test.csv', train=False)\n",
    "X_test, _ = preprocess_data(X_test, scaler)\n",
    "\n",
    "nb_classes = Y_train.shape[1]\n",
    "dims = X_train.shape[1]\n",
    "\n",
    "print(f\"The dataset contains {nb_classes} classes and {dims} features.\")\n",
    "print(f\"Label values: {np.unique(labels)}\")\n",
    "print(f\"\\nFirst three labels: {labels[:3]}\")\n",
    "print(f\"Labels are one-hot encoded for training: \\n{Y_train}\")\n",
    "\n",
    "print(f\"\\nTraining data: \\n{X_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model ...\n",
      "Compile structure ...\n",
      "Fit model ...\n",
      "\u001b[1m1934/1934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272us/step - loss: 1.4390\n",
      "\n",
      "Model description:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">846</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m846\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">848</span> (3.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m848\u001b[0m (3.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">846</span> (3.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m846\u001b[0m (3.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "print(\"Building model ...\")\n",
    "model = Sequential()\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(\"Compile structure ...\")\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "\n",
    "print(\"Fit model ...\")\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print(\"\\nModel description:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras model visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to save image to file:\n",
    "#from keras.utils import plot_model\n",
    "#plot_model(model, to_file='model.png')\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot\n",
    "import keras\n",
    "\n",
    "#Graphical (can also output to file - check documentation)\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dense layer** (for other predefined layers, see [Keras layers](https://keras.io/layers/about-keras-layers/)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "Dense(units, activation=None, use_bias=True, \n",
    "      kernel_initializer='glorot_uniform', bias_initializer='zeros', \n",
    "      kernel_regularizer=None, bias_regularizer=None, \n",
    "      activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "```\n",
    "\n",
    "* `units`: int > 0.\n",
    "\n",
    "* `activation`: name of activation function to use (see [activations](https://keras.io/activations/)), or alternatively, elementwise Theano function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "\n",
    "* `use_bias`: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "\n",
    "* `kernel_initializer`: initializer for the kernel weights matrix (see [initializers](https://keras.io/initializers/)).\n",
    "\n",
    "* `bias_initializer`: initializer for the bias vector (see [initializers](https://keras.io/initializers/)).\n",
    "\n",
    "* `kernel_regularizer`: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "\n",
    "* `bias_regularizer`: instance of WeightRegularizer, applied to the bias.\n",
    "\n",
    "* `activity_regularizer`: instance of ActivityRegularizer, applied to the network output.\n",
    "\n",
    "* `kernel_constraint`: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "\n",
    "* `bias_constraint`: instance of the constraints module, applied to the bias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting\n",
    "\n",
    "As neural networks feature many parameters, they are prone to overfitting. There are many approaches to avoid it, some of them are:\n",
    "\n",
    "* [Keras callbacks](https://keras.io/callbacks/) (EarlyStopping and ModelCheckpoint)\n",
    "* [Dropout layer](https://keras.io/api/layers/regularization_layers/dropout/)\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.8156 - val_loss: 0.7955\n",
      "Epoch 2/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.7844 - val_loss: 0.7798\n",
      "Epoch 3/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 0.7676 - val_loss: 0.7674\n",
      "Epoch 4/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - loss: 0.7577 - val_loss: 0.7570\n",
      "Epoch 5/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - loss: 0.7543 - val_loss: 0.7486\n",
      "Epoch 6/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - loss: 0.7456 - val_loss: 0.7413\n",
      "Epoch 7/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - loss: 0.7319 - val_loss: 0.7355\n",
      "Epoch 8/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 0.7255 - val_loss: 0.7300\n",
      "Epoch 9/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - loss: 0.7268 - val_loss: 0.7255\n",
      "Epoch 10/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - loss: 0.7245 - val_loss: 0.7210\n",
      "Epoch 11/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - loss: 0.7102 - val_loss: 0.7173\n",
      "Epoch 12/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - loss: 0.7008 - val_loss: 0.7140\n",
      "Epoch 13/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - loss: 0.7033 - val_loss: 0.7108\n",
      "Epoch 14/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - loss: 0.7064 - val_loss: 0.7080\n",
      "Epoch 15/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 0.7042 - val_loss: 0.7054\n",
      "Epoch 16/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.6923 - val_loss: 0.7031\n",
      "Epoch 17/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.6946 - val_loss: 0.7010\n",
      "Epoch 18/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 0.6926 - val_loss: 0.6990\n",
      "Epoch 19/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.6875 - val_loss: 0.6972\n",
      "Epoch 20/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 0.6930 - val_loss: 0.6954\n",
      "Epoch 21/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 0.6900 - val_loss: 0.6938\n",
      "Epoch 22/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 0.6794 - val_loss: 0.6924\n",
      "Epoch 23/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - loss: 0.6739 - val_loss: 0.6911\n",
      "Epoch 24/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - loss: 0.6819 - val_loss: 0.6897\n",
      "Epoch 25/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - loss: 0.6731 - val_loss: 0.6887\n",
      "Epoch 26/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 0.6745 - val_loss: 0.6877\n",
      "Epoch 27/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.6786 - val_loss: 0.6864\n",
      "Epoch 28/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.6745 - val_loss: 0.6855\n",
      "Epoch 29/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 0.6757 - val_loss: 0.6844\n",
      "Epoch 30/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 0.6695 - val_loss: 0.6835\n",
      "Epoch 31/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - loss: 0.6708 - val_loss: 0.6826\n",
      "Epoch 32/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.6653 - val_loss: 0.6819\n",
      "Epoch 33/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 0.6656 - val_loss: 0.6811\n",
      "Epoch 34/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - loss: 0.6684 - val_loss: 0.6804\n",
      "Epoch 35/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - loss: 0.6704 - val_loss: 0.6797\n",
      "Epoch 36/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - loss: 0.6630 - val_loss: 0.6790\n",
      "Epoch 37/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - loss: 0.6613 - val_loss: 0.6783\n",
      "Epoch 38/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - loss: 0.6640 - val_loss: 0.6777\n",
      "Epoch 39/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - loss: 0.6663 - val_loss: 0.6772\n",
      "Epoch 40/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - loss: 0.6630 - val_loss: 0.6765\n",
      "Epoch 41/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - loss: 0.6644 - val_loss: 0.6759\n",
      "Epoch 42/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - loss: 0.6567 - val_loss: 0.6755\n",
      "Epoch 43/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - loss: 0.6566 - val_loss: 0.6750\n",
      "Epoch 44/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - loss: 0.6612 - val_loss: 0.6745\n",
      "Epoch 45/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 0.6611 - val_loss: 0.6742\n",
      "Epoch 46/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - loss: 0.6622 - val_loss: 0.6737\n",
      "Epoch 47/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - loss: 0.6628 - val_loss: 0.6733\n",
      "Epoch 48/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 0.6654 - val_loss: 0.6727\n",
      "Epoch 49/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - loss: 0.6645 - val_loss: 0.6722\n",
      "Epoch 50/50\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - loss: 0.6653 - val_loss: 0.6720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a9f33790>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EarlyStopping and ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.15, random_state=42)\n",
    "\n",
    "fBestModel = 'best_model.keras' \n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1) \n",
    "best_model = ModelCheckpoint(fBestModel, verbose=0, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=50, \n",
    "          batch_size=128, verbose=True, callbacks=[best_model, early_stop]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer deep dense networks with Keras\n",
    "\n",
    "Keras offers two API-s to model neural network structure - Sequential API and Functional API. Using a sequential API, modelling a deep MLP can be done in only a few lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 1.5995 - val_loss: 0.8802\n",
      "Epoch 2/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 0.8334 - val_loss: 0.7876\n",
      "Epoch 3/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.7573 - val_loss: 0.7506\n",
      "Epoch 4/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 0.7316 - val_loss: 0.7294\n",
      "Epoch 5/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 0.7100 - val_loss: 0.7144\n",
      "Epoch 6/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 0.6976 - val_loss: 0.7052\n",
      "Epoch 7/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.6924 - val_loss: 0.6973\n",
      "Epoch 8/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 0.6792 - val_loss: 0.6918\n",
      "Epoch 9/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 0.6744 - val_loss: 0.6879\n",
      "Epoch 10/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 0.6635 - val_loss: 0.6829\n",
      "Epoch 11/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 0.6718 - val_loss: 0.6802\n",
      "Epoch 12/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 0.6579 - val_loss: 0.6780\n",
      "Epoch 13/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.6574 - val_loss: 0.6755\n",
      "Epoch 14/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 0.6608 - val_loss: 0.6734\n",
      "Epoch 15/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 0.6567 - val_loss: 0.6721\n",
      "Epoch 16/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 0.6496 - val_loss: 0.6702\n",
      "Epoch 17/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 0.6506 - val_loss: 0.6688\n",
      "Epoch 18/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 0.6544 - val_loss: 0.6674\n",
      "Epoch 19/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.6425 - val_loss: 0.6664\n",
      "Epoch 20/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 0.6484 - val_loss: 0.6653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2bdfc62c0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=20, \n",
    "          batch_size=128, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Test example: \n",
      "\t[[-0.2535081  -0.21010602 -0.30716544 -0.27944276 -0.1618665  -0.11933088\n",
      "  -0.18804485 -0.29366383 -0.29103777  2.52563    -0.41181517 -0.24841812\n",
      "  -0.23873688  0.41202334  0.18528318 -0.1857286  -0.2478012  -0.4307139\n",
      "  -0.11900038 -0.3277401  -0.29310533 -0.50474644 -0.18202722  0.5089937\n",
      "   0.6281596   0.25544888  0.10559219 -0.28857473 -0.1450437  -0.09160521\n",
      "  -0.165688   -0.43188646  0.23163353 -0.28095117 -0.20834123  0.11385515\n",
      "  -0.34829164  0.260751   -0.14722317 -0.19791047 -0.27952313 -0.35591894\n",
      "  -0.26444665 -0.41663927 -0.09204473 -0.2731184  -0.17263882 -0.61500263\n",
      "  -0.25436136 -0.18848683 -0.10373055 -0.20433451 -0.22031906 -0.5038467\n",
      "  -0.32352898 -0.15774053 -0.28564557 -0.17520699 -0.15075752 -0.34008545\n",
      "  -0.2356121  -0.44532695 -0.17818491  0.5123979  -0.28379902 -0.4197967\n",
      "  -0.58252704 -0.2231081   0.04594234  0.0552249  -0.2746733   0.05858203\n",
      "  -0.10220148 -0.15430625 -0.2271255  -0.25631952 -0.13698885 -0.13188471\n",
      "  -0.23370849 -0.3108527  -0.17010848 -0.2247894  -0.20399979 -0.06144607\n",
      "  -0.2800985   3.681262    0.38494045  9.040672   -0.29971188 -0.17669907\n",
      "  -0.1295155  -0.3869381  -0.10496315]]\n",
      "Predicted vector: \n",
      "\t[[1.3005799e-06 2.5249326e-01 4.1900623e-01 3.1926876e-01 3.3672443e-06\n",
      "  4.4270287e-06 9.2223529e-03 8.7626994e-08 1.0657703e-07]]\n",
      "Predicted class index: \n",
      "\t2\n"
     ]
    }
   ],
   "source": [
    "firstTestExample = X_test[:1]\n",
    "prediction = model.predict(firstTestExample)\n",
    "predictedClass = np.argmax(prediction)\n",
    "\n",
    "print(f\"Test example: \\n\\t{firstTestExample}\")\n",
    "print(f\"Predicted vector: \\n\\t{prediction}\")\n",
    "print(f\"Predicted class index: \\n\\t{predictedClass}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on - create and test your own structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - loss: 1.6087 - val_loss: 0.8814\n",
      "Epoch 2/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.8500 - val_loss: 0.7878\n",
      "Epoch 3/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 0.7709 - val_loss: 0.7496\n",
      "Epoch 4/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 0.7321 - val_loss: 0.7276\n",
      "Epoch 5/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 0.7151 - val_loss: 0.7141\n",
      "Epoch 6/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 0.6952 - val_loss: 0.7037\n",
      "Epoch 7/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 0.6903 - val_loss: 0.6954\n",
      "Epoch 8/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 0.6906 - val_loss: 0.6901\n",
      "Epoch 9/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 0.6739 - val_loss: 0.6855\n",
      "Epoch 10/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 0.6657 - val_loss: 0.6818\n",
      "Epoch 11/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 0.6585 - val_loss: 0.6789\n",
      "Epoch 12/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 0.6619 - val_loss: 0.6761\n",
      "Epoch 13/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.6571 - val_loss: 0.6736\n",
      "Epoch 14/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 0.6635 - val_loss: 0.6720\n",
      "Epoch 15/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 0.6592 - val_loss: 0.6702\n",
      "Epoch 16/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 0.6580 - val_loss: 0.6688\n",
      "Epoch 17/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.6425 - val_loss: 0.6678\n",
      "Epoch 18/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 0.6514 - val_loss: 0.6667\n",
      "Epoch 19/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 0.6457 - val_loss: 0.6653\n",
      "Epoch 20/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 0.6486 - val_loss: 0.6642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a9e04a90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100))\n",
    "\n",
    "# TODO: update model HERE and observe differences!\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=20, \n",
    "          batch_size=128, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other neural networks architectures\n",
    "\n",
    "There exist some known neural networks architectures as shown in the Figure below:\n",
    "    \n",
    "<img src=\"imgs/dl_overview.png\" >\n",
    "\n",
    "Credits: Yam Peleg ([@Yampeleg](https://twitter.com/yampeleg)) \n",
    "   \n",
    "### Convolutional neural networks (CNNs)\n",
    "\n",
    "<img src=\"imgs/same_padding_no_strides.gif\" width=\"50%\">\n",
    "\n",
    "*Image from*: [http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html](http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html)\n",
    "\n",
    "The first layer in a CNN is always a convolutional layer. \n",
    "\n",
    "After each convolutional layer, it is convention to apply a nonlinear layer (or activation layer, e.g. ReLU) immediately afterward. The purpose of this layer is to introduce nonlinearity to a system that basically has just been computing linear operations during the conv layers (just element wise multiplications and summations). It has been found out that ReLU layers work far better because the network is able to train a lot faster (because of the computational efficiency) without making a significant difference to the accuracy.\n",
    "\n",
    "After some ReLU layers, it is customary to apply a pooling layer (i.e. downsampling layer). As it reduces the number of parameters it can also be used to control overfitting. In this category, there are also several layer options, with maxpooling being the most popular:\n",
    "\n",
    "<img src=\"imgs/MaxPool.png\" width=\"80%\" />\n",
    "\n",
    "The last layer, however, is an important one, namely the fully connected layer. A fully connected layer looks at what high level features most strongly correlate to a particular class and has particular weights so that when you compute the products between the weights and the previous layer, you get the correct probabilities for the different classes.\n",
    "\n",
    "<img src=\"imgs/ConvNet LeNet.png\" width=\"90%\" />\n",
    "\n",
    "Check more about convolutional layer in [Keras documentation](https://keras.io/layers/convolutional/) or check [IMDB classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_cnn.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent neural networks (RNNs) and Long short term memory neural networks (LSTMs)\n",
    "\n",
    "<img src=\"imgs/rnn.png\" width=\"60%\">\n",
    "\n",
    "A recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This creates an internal state of the network which allows it to exhibit dynamic temporal behavior.\n",
    "\n",
    "An LSTM network is an artificial neural network that contains LSTM blocks instead of, or in addition to, regular network units. A LSTM block may be described as a \"smart\" network unit that can remember a value for an arbitrary length of time. Unlike traditional RNNs, an Long short-term memory network is well-suited to learn from experience to classify, process and predict time series when there are very long time lags of unknown size between important events.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"imgs/gru_wiki.png\" width=\"100%\"></td>\n",
    "        <td><img src=\"imgs/lstm.png\" width=\"100%\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<img src=\"imgs/gru.png\" width=\"60%\">\n",
    "\n",
    "#### IMDB sentiment classification task\n",
    "\n",
    "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets.\n",
    "\n",
    "IMDB provided a set of 25,000 highly polar movie reviews for training, and 25,000 for testing.\n",
    "\n",
    "**Data preparation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "First example:\n",
      "[[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]]\n",
      "Pad sequences ...\n",
      "X_train shape: (25000, 100)\n",
      "X_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 100  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(\"Loading data...\")\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('First example:')\n",
    "print(X_train[:1])\n",
    "\n",
    "print(\"Pad sequences ...\")\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hands-on** - play with layers to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Epoch 1/4\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - accuracy: 0.5188 - loss: 0.7324 - val_accuracy: 0.5897 - val_loss: 0.6591\n",
      "Epoch 2/4\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.6728 - loss: 0.6019 - val_accuracy: 0.7549 - val_loss: 0.5154\n",
      "Epoch 3/4\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.7704 - loss: 0.4996 - val_accuracy: 0.7884 - val_loss: 0.4845\n",
      "Epoch 4/4\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.7918 - loss: 0.4565 - val_accuracy: 0.7304 - val_loss: 0.5402\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7295 - loss: 0.5436\n",
      "Test accuracy: 0.7304400205612183\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "\n",
    "# TODO: try changing\n",
    "model.add(SimpleRNN(128))  \n",
    "#model.add(GRU(128))  \n",
    "#model.add(LSTM(128))  \n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(\"Train...\")\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=4, validation_data=(X_test, y_test))\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "\n",
    "\"Word embeddings\" are a family of natural language processing techniques aiming at mapping semantic meaning into a geometric space. This is done by associating a numeric vector to every word in a dictionary, such that the distance (e.g. L2 distance or more commonly cosine distance) between any two vectors would capture part of the semantic relationship between the two associated words. The geometric space formed by these vectors is called an embedding space.\n",
    "\n",
    "Embeddings convert words to vectors in a high dimensional space. Each dimension denotes an aspect like gender, type of object / word. By converting words to vectors we build relations between words. More similar the words in a dimension, more closer their scores are.\n",
    "\n",
    "Training algorithms:\n",
    "\n",
    "<img src=\"imgs/cbow_skipgram.png\" width=\"80%\" />\n",
    "\n",
    "Credits: Mikolov et al. (2013), [Exploiting Similarities among Languages for Machine Translation](https://arxiv.org/pdf/1309.4168v1.pdf)\n",
    "\n",
    "### Word2Vec example\n",
    "\n",
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts: 4842\n",
      "First post: \n",
      "\t['Well, everyone got up and going this morning.  It\\'s still raining, but that\\'s okay with me.  Sort of suits my mood.  I could easily have stayed home in bed with my book and the cats.  This has been a lot of rain though!  People have wet basements, there are lakes where there should be golf courses and fields, everything is green, green, green.  But, it is supposed to be 26 degrees by Friday, so we\\'ll be dealing with mosquitos next week.  I heard Winnipeg described as an \"Old Testament\" city on  urlLink CBC Radio One  last week and it sort of rings true.  Floods, infestations, etc., etc..']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "DATA_DIRECTORY = os.path.join(os.path.abspath(os.path.curdir), 'data', 'word_embeddings')\n",
    "male_posts = []\n",
    "female_post = []\n",
    "with open(os.path.join(DATA_DIRECTORY,\"male_blog_list.txt\"),\"rb\") as male_file:\n",
    "    male_posts= pickle.load(male_file)\n",
    "    \n",
    "with open(os.path.join(DATA_DIRECTORY,\"female_blog_list.txt\"),\"rb\") as female_file:\n",
    "    female_posts = pickle.load(female_file)\n",
    "filtered_male_posts = list(filter(lambda p: len(p) > 0, male_posts))\n",
    "filtered_female_posts = list(filter(lambda p: len(p) > 0, female_posts))\n",
    "posts = filtered_female_posts + filtered_male_posts\n",
    "\n",
    "print(\"Number of posts: {}\".format(len(posts)))\n",
    "print(\"First post: \\n\\t{}\".format(posts[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model = Word2Vec(vector_size=200, min_count=1)\n",
    "model.build_vocab(map(lambda x: x.split(), posts), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'I': 1,\n",
       " 'to': 2,\n",
       " 'and': 3,\n",
       " 'a': 4,\n",
       " 'of': 5,\n",
       " 'that': 6,\n",
       " 'in': 7,\n",
       " 'my': 8,\n",
       " 'is': 9,\n",
       " 'it': 10,\n",
       " 'for': 11,\n",
       " 'was': 12,\n",
       " 'you': 13,\n",
       " 'have': 14,\n",
       " 'with': 15,\n",
       " 'on': 16,\n",
       " 'be': 17,\n",
       " 'but': 18,\n",
       " 'me': 19,\n",
       " 'i': 20,\n",
       " 'this': 21,\n",
       " 'so': 22,\n",
       " 'not': 23,\n",
       " 'at': 24,\n",
       " 'all': 25,\n",
       " 'just': 26,\n",
       " 'as': 27,\n",
       " \"I'm\": 28,\n",
       " 'are': 29,\n",
       " 'like': 30,\n",
       " 'about': 31,\n",
       " 'we': 32,\n",
       " 'or': 33,\n",
       " 'The': 34,\n",
       " 'out': 35,\n",
       " 'up': 36,\n",
       " 'from': 37,\n",
       " 'what': 38,\n",
       " 'he': 39,\n",
       " 'had': 40,\n",
       " 'get': 41,\n",
       " 'one': 42,\n",
       " 'will': 43,\n",
       " 'do': 44,\n",
       " 'they': 45,\n",
       " 'know': 46,\n",
       " 'can': 47,\n",
       " 'if': 48,\n",
       " 'some': 49,\n",
       " '-': 50,\n",
       " 'really': 51,\n",
       " \"don't\": 52,\n",
       " 'an': 53,\n",
       " 'your': 54,\n",
       " 'by': 55,\n",
       " 'when': 56,\n",
       " 'am': 57,\n",
       " 'think': 58,\n",
       " 'her': 59,\n",
       " 'urlLink': 60,\n",
       " 'would': 61,\n",
       " 'more': 62,\n",
       " 'And': 63,\n",
       " 'been': 64,\n",
       " 'his': 65,\n",
       " 'has': 66,\n",
       " 'time': 67,\n",
       " 'go': 68,\n",
       " 'she': 69,\n",
       " 'going': 70,\n",
       " 'then': 71,\n",
       " 'It': 72,\n",
       " 'there': 73,\n",
       " 'people': 74,\n",
       " 'got': 75,\n",
       " 'because': 76,\n",
       " 'want': 77,\n",
       " 'how': 78,\n",
       " 'no': 79,\n",
       " 'were': 80,\n",
       " \"it's\": 81,\n",
       " 'who': 82,\n",
       " 'good': 83,\n",
       " 'back': 84,\n",
       " 'only': 85,\n",
       " 'But': 86,\n",
       " 'see': 87,\n",
       " 'into': 88,\n",
       " 'much': 89,\n",
       " 'even': 90,\n",
       " 'could': 91,\n",
       " 'it.': 92,\n",
       " 'them': 93,\n",
       " 'make': 94,\n",
       " 'over': 95,\n",
       " 'now': 96,\n",
       " 'other': 97,\n",
       " 'So': 98,\n",
       " \"I've\": 99,\n",
       " 'our': 100,\n",
       " 'their': 101,\n",
       " 'which': 102,\n",
       " 'You': 103,\n",
       " 'than': 104,\n",
       " 'feel': 105,\n",
       " 'very': 106,\n",
       " 'something': 107,\n",
       " 'still': 108,\n",
       " 'him': 109,\n",
       " 'never': 110,\n",
       " 'things': 111,\n",
       " 'love': 112,\n",
       " 'me.': 113,\n",
       " 'its': 114,\n",
       " 'went': 115,\n",
       " 'last': 116,\n",
       " 'little': 117,\n",
       " 'did': 118,\n",
       " 'need': 119,\n",
       " 'He': 120,\n",
       " 'new': 121,\n",
       " 'way': 122,\n",
       " 'after': 123,\n",
       " 'being': 124,\n",
       " 'around': 125,\n",
       " 'My': 126,\n",
       " \"It's\": 127,\n",
       " \"I'll\": 128,\n",
       " 'should': 129,\n",
       " 'This': 130,\n",
       " 'too': 131,\n",
       " 'first': 132,\n",
       " 'A': 133,\n",
       " 'say': 134,\n",
       " 'day': 135,\n",
       " 'any': 136,\n",
       " \"can't\": 137,\n",
       " 'off': 138,\n",
       " 'where': 139,\n",
       " 'down': 140,\n",
       " 'thing': 141,\n",
       " 'take': 142,\n",
       " 'right': 143,\n",
       " 'We': 144,\n",
       " 'life': 145,\n",
       " \"didn't\": 146,\n",
       " 'two': 147,\n",
       " 'those': 148,\n",
       " 'most': 149,\n",
       " 'made': 150,\n",
       " 'work': 151,\n",
       " 'through': 152,\n",
       " 'here': 153,\n",
       " 'also': 154,\n",
       " 'said': 155,\n",
       " 'If': 156,\n",
       " 'thought': 157,\n",
       " 'always': 158,\n",
       " 'come': 159,\n",
       " 'find': 160,\n",
       " 'these': 161,\n",
       " '.': 162,\n",
       " 'myself': 163,\n",
       " 'me,': 164,\n",
       " 'next': 165,\n",
       " 'long': 166,\n",
       " 'before': 167,\n",
       " 'ever': 168,\n",
       " 'us': 169,\n",
       " 'why': 170,\n",
       " 'well': 171,\n",
       " 'many': 172,\n",
       " 'might': 173,\n",
       " 'since': 174,\n",
       " 'few': 175,\n",
       " 'it,': 176,\n",
       " 'look': 177,\n",
       " \"that's\": 178,\n",
       " 'someone': 179,\n",
       " 'In': 180,\n",
       " 'better': 181,\n",
       " 'pretty': 182,\n",
       " 'getting': 183,\n",
       " 'doing': 184,\n",
       " 'She': 185,\n",
       " 'im': 186,\n",
       " 'put': 187,\n",
       " 'while': 188,\n",
       " 'They': 189,\n",
       " 'every': 190,\n",
       " 'lot': 191,\n",
       " 'another': 192,\n",
       " 'best': 193,\n",
       " 'tell': 194,\n",
       " 'give': 195,\n",
       " 'night': 196,\n",
       " 'sure': 197,\n",
       " 'actually': 198,\n",
       " 'home': 199,\n",
       " 'What': 200,\n",
       " 'away': 201,\n",
       " 'world': 202,\n",
       " 'probably': 203,\n",
       " 'same': 204,\n",
       " 'came': 205,\n",
       " 'such': 206,\n",
       " 'maybe': 207,\n",
       " 'nothing': 208,\n",
       " 'keep': 209,\n",
       " 'today': 210,\n",
       " 'let': 211,\n",
       " 'may': 212,\n",
       " 'trying': 213,\n",
       " 'anything': 214,\n",
       " 'great': 215,\n",
       " 'own': 216,\n",
       " 'That': 217,\n",
       " 'everything': 218,\n",
       " 'try': 219,\n",
       " 'friends': 220,\n",
       " 'guess': 221,\n",
       " 'school': 222,\n",
       " 'bad': 223,\n",
       " 'until': 224,\n",
       " 'now.': 225,\n",
       " 'whole': 226,\n",
       " '2': 227,\n",
       " 'enough': 228,\n",
       " 'told': 229,\n",
       " 'start': 230,\n",
       " \"doesn't\": 231,\n",
       " 'that.': 232,\n",
       " 'dont': 233,\n",
       " 'time.': 234,\n",
       " 'hope': 235,\n",
       " \"you're\": 236,\n",
       " 'Well,': 237,\n",
       " 'end': 238,\n",
       " 'help': 239,\n",
       " 'without': 240,\n",
       " 'talk': 241,\n",
       " 'person': 242,\n",
       " 'hard': 243,\n",
       " 'left': 244,\n",
       " 'having': 245,\n",
       " 'days': 246,\n",
       " 'done': 247,\n",
       " 'old': 248,\n",
       " 'believe': 249,\n",
       " 'use': 250,\n",
       " 'started': 251,\n",
       " 'found': 252,\n",
       " 'year': 253,\n",
       " 'place': 254,\n",
       " 'God': 255,\n",
       " 'As': 256,\n",
       " 'bit': 257,\n",
       " 'again': 258,\n",
       " 'There': 259,\n",
       " 'blog': 260,\n",
       " 'everyone': 261,\n",
       " 'Not': 262,\n",
       " 'least': 263,\n",
       " 'wanted': 264,\n",
       " 'Then': 265,\n",
       " 'each': 266,\n",
       " 'call': 267,\n",
       " 'does': 268,\n",
       " 'though': 269,\n",
       " 'looking': 270,\n",
       " 'When': 271,\n",
       " 'quite': 272,\n",
       " 'part': 273,\n",
       " 'gonna': 274,\n",
       " 'nice': 275,\n",
       " '..': 276,\n",
       " 'post': 277,\n",
       " 'years': 278,\n",
       " 'able': 279,\n",
       " 'read': 280,\n",
       " 'used': 281,\n",
       " 'Just': 282,\n",
       " 'kind': 283,\n",
       " 'makes': 284,\n",
       " 'mean': 285,\n",
       " 'How': 286,\n",
       " 'now,': 287,\n",
       " '--': 288,\n",
       " 'called': 289,\n",
       " 'decided': 290,\n",
       " 'again.': 291,\n",
       " 'Best': 292,\n",
       " 'friend': 293,\n",
       " 'big': 294,\n",
       " 'seems': 295,\n",
       " 'week': 296,\n",
       " \"wasn't\": 297,\n",
       " 'All': 298,\n",
       " \"I'd\": 299,\n",
       " 'took': 300,\n",
       " 'happy': 301,\n",
       " 'you.': 302,\n",
       " 'almost': 303,\n",
       " 'head': 304,\n",
       " 'must': 305,\n",
       " 'Now': 306,\n",
       " 'making': 307,\n",
       " 'mind': 308,\n",
       " 'For': 309,\n",
       " 'remember': 310,\n",
       " 'play': 311,\n",
       " 'talking': 312,\n",
       " 'thinking': 313,\n",
       " 'else': 314,\n",
       " 'house': 315,\n",
       " 'them.': 316,\n",
       " 'far': 317,\n",
       " 'once': 318,\n",
       " 'fun': 319,\n",
       " 'Oh': 320,\n",
       " 'hate': 321,\n",
       " 'felt': 322,\n",
       " 'both': 323,\n",
       " '...': 324,\n",
       " 'movie': 325,\n",
       " 'stuff': 326,\n",
       " 'One': 327,\n",
       " 'live': 328,\n",
       " 'finally': 329,\n",
       " 'working': 330,\n",
       " \"won't\": 331,\n",
       " 'Well': 332,\n",
       " 'write': 333,\n",
       " 'past': 334,\n",
       " 'already': 335,\n",
       " 'saw': 336,\n",
       " 'anyone': 337,\n",
       " 'day.': 338,\n",
       " 'wish': 339,\n",
       " 'leave': 340,\n",
       " 'couple': 341,\n",
       " 'three': 342,\n",
       " 'No': 343,\n",
       " 'feeling': 344,\n",
       " 'coming': 345,\n",
       " ',': 346,\n",
       " \"there's\": 347,\n",
       " 'guy': 348,\n",
       " \"isn't\": 349,\n",
       " 'To': 350,\n",
       " 'you,': 351,\n",
       " 'hours': 352,\n",
       " 'yet': 353,\n",
       " 'up.': 354,\n",
       " 'life.': 355,\n",
       " 'half': 356,\n",
       " 'Maybe': 357,\n",
       " 'real': 358,\n",
       " 'heart': 359,\n",
       " 'show': 360,\n",
       " 'different': 361,\n",
       " 'asked': 362,\n",
       " '3': 363,\n",
       " 'time,': 364,\n",
       " 'him.': 365,\n",
       " \"haven't\": 366,\n",
       " 'game': 367,\n",
       " 'stop': 368,\n",
       " \"i'm\": 369,\n",
       " 'well,': 370,\n",
       " 'out.': 371,\n",
       " 'Today': 372,\n",
       " 'After': 373,\n",
       " 'man': 374,\n",
       " 'So,': 375,\n",
       " 'Your': 376,\n",
       " 'watch': 377,\n",
       " 'that,': 378,\n",
       " 'times': 379,\n",
       " 'today.': 380,\n",
       " 'care': 381,\n",
       " 'Why': 382,\n",
       " 'well.': 383,\n",
       " 'fact': 384,\n",
       " 'knew': 385,\n",
       " 'there.': 386,\n",
       " 'I’m': 387,\n",
       " \"That's\": 388,\n",
       " 'eyes': 389,\n",
       " 'seen': 390,\n",
       " 'become': 391,\n",
       " 'name': 392,\n",
       " 'Its': 393,\n",
       " 'face': 394,\n",
       " 'seem': 395,\n",
       " \"he's\": 396,\n",
       " \"we're\": 397,\n",
       " 'Or': 398,\n",
       " 'rather': 399,\n",
       " 'taking': 400,\n",
       " 'good.': 401,\n",
       " 'tried': 402,\n",
       " 'set': 403,\n",
       " 'change': 404,\n",
       " 'turn': 405,\n",
       " 'job': 406,\n",
       " 'wonder': 407,\n",
       " 'reading': 408,\n",
       " 'THE': 409,\n",
       " 'second': 410,\n",
       " 'looked': 411,\n",
       " 'between': 412,\n",
       " 'cool': 413,\n",
       " 'At': 414,\n",
       " 'free': 415,\n",
       " 'point': 416,\n",
       " 'morning': 417,\n",
       " 'thats': 418,\n",
       " 'computer': 419,\n",
       " 'means': 420,\n",
       " 'run': 421,\n",
       " 'reason': 422,\n",
       " 'idea': 423,\n",
       " 'do.': 424,\n",
       " 'gets': 425,\n",
       " 'hear': 426,\n",
       " 'mom': 427,\n",
       " 'girl': 428,\n",
       " 'during': 429,\n",
       " 'behind': 430,\n",
       " 'know,': 431,\n",
       " 'less': 432,\n",
       " 'miss': 433,\n",
       " 'family': 434,\n",
       " 'lost': 435,\n",
       " 'gave': 436,\n",
       " 'saying': 437,\n",
       " 'understand': 438,\n",
       " 'comes': 439,\n",
       " 'completely': 440,\n",
       " 'too.': 441,\n",
       " 'wants': 442,\n",
       " 'playing': 443,\n",
       " 'small': 444,\n",
       " 'supposed': 445,\n",
       " 'gone': 446,\n",
       " '4': 447,\n",
       " 'ask': 448,\n",
       " 'money': 449,\n",
       " 'against': 450,\n",
       " 'tired': 451,\n",
       " 'again,': 452,\n",
       " 'room': 453,\n",
       " 'all.': 454,\n",
       " 'later': 455,\n",
       " 'full': 456,\n",
       " 'hell': 457,\n",
       " 'His': 458,\n",
       " 'New': 459,\n",
       " 'cause': 460,\n",
       " 'wait': 461,\n",
       " 'car': 462,\n",
       " 'stupid': 463,\n",
       " 'watching': 464,\n",
       " 'one.': 465,\n",
       " 'sleep': 466,\n",
       " 'under': 467,\n",
       " 'move': 468,\n",
       " 'turned': 469,\n",
       " 'here.': 470,\n",
       " 'says': 471,\n",
       " 'seeing': 472,\n",
       " 'On': 473,\n",
       " 'close': 474,\n",
       " 'rest': 475,\n",
       " 'stay': 476,\n",
       " 'side': 477,\n",
       " 'up,': 478,\n",
       " 'heard': 479,\n",
       " 'fun.': 480,\n",
       " 'there,': 481,\n",
       " 'happened': 482,\n",
       " 'running': 483,\n",
       " 'phone': 484,\n",
       " 'goes': 485,\n",
       " 'interesting': 486,\n",
       " 'problem': 487,\n",
       " 'along': 488,\n",
       " 'words': 489,\n",
       " '5': 490,\n",
       " \"couldn't\": 491,\n",
       " 'walk': 492,\n",
       " 'writing': 493,\n",
       " 'her.': 494,\n",
       " 'oh': 495,\n",
       " 'matter': 496,\n",
       " 'looks': 497,\n",
       " 'knows': 498,\n",
       " 'soon': 499,\n",
       " 'played': 500,\n",
       " 'kinda': 501,\n",
       " \"Don't\": 502,\n",
       " 'spent': 503,\n",
       " \"wouldn't\": 504,\n",
       " 'know.': 505,\n",
       " 'living': 506,\n",
       " 'sitting': 507,\n",
       " \"they're\": 508,\n",
       " 'weekend': 509,\n",
       " 'today,': 510,\n",
       " 'minutes': 511,\n",
       " 'day,': 512,\n",
       " 'sort': 513,\n",
       " 'buy': 514,\n",
       " 'spend': 515,\n",
       " 'on.': 516,\n",
       " 'Do': 517,\n",
       " 'night.': 518,\n",
       " 'wrong': 519,\n",
       " 'front': 520,\n",
       " '1': 521,\n",
       " 'guys': 522,\n",
       " 'Is': 523,\n",
       " 'hold': 524,\n",
       " 'kids': 525,\n",
       " 'all,': 526,\n",
       " 'waiting': 527,\n",
       " 'course': 528,\n",
       " 'story': 529,\n",
       " 'others': 530,\n",
       " 'eat': 531,\n",
       " 'together': 532,\n",
       " 'word': 533,\n",
       " 'is,': 534,\n",
       " 'site': 535,\n",
       " 'worth': 536,\n",
       " 'parents': 537,\n",
       " 'light': 538,\n",
       " 'hit': 539,\n",
       " '\"I': 540,\n",
       " 'tomorrow': 541,\n",
       " 'brought': 542,\n",
       " 'instead': 543,\n",
       " 'whatever': 544,\n",
       " 'moment': 545,\n",
       " 'open': 546,\n",
       " 'people.': 547,\n",
       " 'Im': 548,\n",
       " 'book': 549,\n",
       " 'back.': 550,\n",
       " 'u': 551,\n",
       " 'is.': 552,\n",
       " 'out,': 553,\n",
       " 'say,': 554,\n",
       " 'him,': 555,\n",
       " 'though,': 556,\n",
       " 'ready': 557,\n",
       " 'Who': 558,\n",
       " 'way.': 559,\n",
       " 'high': 560,\n",
       " 'months': 561,\n",
       " '(': 562,\n",
       " 'don’t': 563,\n",
       " 'sit': 564,\n",
       " 'funny': 565,\n",
       " 'bring': 566,\n",
       " 'life,': 567,\n",
       " 'American': 568,\n",
       " 'top': 569,\n",
       " 'starting': 570,\n",
       " 'this.': 571,\n",
       " 'though.': 572,\n",
       " 'important': 573,\n",
       " 'to.': 574,\n",
       " 'inside': 575,\n",
       " 'myself.': 576,\n",
       " 'hot': 577,\n",
       " '10': 578,\n",
       " 'fucking': 579,\n",
       " 'hour': 580,\n",
       " 'weeks': 581,\n",
       " 'simply': 582,\n",
       " 'summer': 583,\n",
       " 'Of': 584,\n",
       " 'way,': 585,\n",
       " 'using': 586,\n",
       " 'dad': 587,\n",
       " 'damn': 588,\n",
       " 'learn': 589,\n",
       " 'upon': 590,\n",
       " 'sometimes': 591,\n",
       " 'cannot': 592,\n",
       " 'this,': 593,\n",
       " 'order': 594,\n",
       " 'especially': 595,\n",
       " 'water': 596,\n",
       " 'true': 597,\n",
       " 'figure': 598,\n",
       " 'Oh,': 599,\n",
       " 'class': 600,\n",
       " 'bed': 601,\n",
       " 'music': 602,\n",
       " 'check': 603,\n",
       " 'yesterday': 604,\n",
       " '2.': 605,\n",
       " 'thing.': 606,\n",
       " \"she's\": 607,\n",
       " 'watched': 608,\n",
       " 'here,': 609,\n",
       " 'crazy': 610,\n",
       " 'year.': 611,\n",
       " 'didnt': 612,\n",
       " 'fall': 613,\n",
       " ':)': 614,\n",
       " 'exactly': 615,\n",
       " 'kept': 616,\n",
       " 'Even': 617,\n",
       " 'Last': 618,\n",
       " 'With': 619,\n",
       " 'within': 620,\n",
       " 'finished': 621,\n",
       " 'ended': 622,\n",
       " 'either': 623,\n",
       " 'taken': 624,\n",
       " 'film': 625,\n",
       " 'shit': 626,\n",
       " 'pay': 627,\n",
       " 'Anyways,': 628,\n",
       " 'thoughts': 629,\n",
       " 'them,': 630,\n",
       " 'outside': 631,\n",
       " 'song': 632,\n",
       " 'online': 633,\n",
       " 'totally': 634,\n",
       " 'given': 635,\n",
       " 'five': 636,\n",
       " 'be.': 637,\n",
       " 'needed': 638,\n",
       " 'hand': 639,\n",
       " 'realize': 640,\n",
       " 'However,': 641,\n",
       " 'deal': 642,\n",
       " 'certain': 643,\n",
       " 'Because': 644,\n",
       " 'break': 645,\n",
       " 'often': 646,\n",
       " 'dream': 647,\n",
       " 'late': 648,\n",
       " 'wanna': 649,\n",
       " 'number': 650,\n",
       " 'telling': 651,\n",
       " 'sense': 652,\n",
       " 'Anyway,': 653,\n",
       " 'truly': 654,\n",
       " 'night,': 655,\n",
       " 'hands': 656,\n",
       " 'away.': 657,\n",
       " 'short': 658,\n",
       " 'work.': 659,\n",
       " 'meet': 660,\n",
       " 'walked': 661,\n",
       " 'test': 662,\n",
       " 'onto': 663,\n",
       " 'known': 664,\n",
       " 'longer': 665,\n",
       " 'home.': 666,\n",
       " 'Okay,': 667,\n",
       " 'single': 668,\n",
       " 'cant': 669,\n",
       " 'Some': 670,\n",
       " 'met': 671,\n",
       " 'off.': 672,\n",
       " 'hair': 673,\n",
       " 'sound': 674,\n",
       " 'more.': 675,\n",
       " 'body': 676,\n",
       " 'till': 677,\n",
       " 'in.': 678,\n",
       " 'people,': 679,\n",
       " 'mad': 680,\n",
       " '6': 681,\n",
       " 'alone': 682,\n",
       " 'Which': 683,\n",
       " 'stuff.': 684,\n",
       " 'needs': 685,\n",
       " 'chance': 686,\n",
       " 'hurt': 687,\n",
       " 'shall': 688,\n",
       " ':': 689,\n",
       " 'talked': 690,\n",
       " 'happen': 691,\n",
       " 'ago': 692,\n",
       " 'realized': 693,\n",
       " 'Mr.': 694,\n",
       " 'sick': 695,\n",
       " 'things.': 696,\n",
       " 'But,': 697,\n",
       " 'Current': 698,\n",
       " 'blog.': 699,\n",
       " 'week.': 700,\n",
       " 'feels': 701,\n",
       " 'seemed': 702,\n",
       " '(I': 703,\n",
       " 'awesome': 704,\n",
       " 'course,': 705,\n",
       " 'across': 706,\n",
       " 'human': 707,\n",
       " 'something.': 708,\n",
       " 'ones': 709,\n",
       " \"you'll\": 710,\n",
       " 'yourself': 711,\n",
       " 'changed': 712,\n",
       " 'mean,': 713,\n",
       " 'early': 714,\n",
       " 'special': 715,\n",
       " 'sorry': 716,\n",
       " '(and': 717,\n",
       " 'her,': 718,\n",
       " 'not.': 719,\n",
       " 'on,': 720,\n",
       " 'walking': 721,\n",
       " 'us.': 722,\n",
       " 'drive': 723,\n",
       " 'forward': 724,\n",
       " 'huge': 725,\n",
       " 'Lord': 726,\n",
       " 'food': 727,\n",
       " 'learned': 728,\n",
       " 'go.': 729,\n",
       " 'power': 730,\n",
       " 'Like': 731,\n",
       " 'tonight': 732,\n",
       " 'pick': 733,\n",
       " 'usually': 734,\n",
       " 'brother': 735,\n",
       " 'question': 736,\n",
       " 'school.': 737,\n",
       " 'email': 738,\n",
       " \"He's\": 739,\n",
       " 'easy': 740,\n",
       " 'it?': 741,\n",
       " 'work,': 742,\n",
       " 'band': 743,\n",
       " 'except': 744,\n",
       " 'By': 745,\n",
       " 'lack': 746,\n",
       " 'John': 747,\n",
       " 'bought': 748,\n",
       " 'enjoy': 749,\n",
       " \"aren't\": 750,\n",
       " 'cool.': 751,\n",
       " 'lives': 752,\n",
       " 'whether': 753,\n",
       " 'girls': 754,\n",
       " 'written': 755,\n",
       " 'takes': 756,\n",
       " 'do,': 757,\n",
       " 'glad': 758,\n",
       " 'bad.': 759,\n",
       " 'dark': 760,\n",
       " 'four': 761,\n",
       " 'pain': 762,\n",
       " 'about.': 763,\n",
       " 'sister': 764,\n",
       " 'please': 765,\n",
       " 'stand': 766,\n",
       " '\"The': 767,\n",
       " 'problems': 768,\n",
       " 'dear': 769,\n",
       " \"There's\": 770,\n",
       " 'sun': 771,\n",
       " 'weird': 772,\n",
       " 'OF': 773,\n",
       " '\"': 774,\n",
       " 'team': 775,\n",
       " 'black': 776,\n",
       " 'personal': 777,\n",
       " 'myself,': 778,\n",
       " 'lots': 779,\n",
       " 'People': 780,\n",
       " 'middle': 781,\n",
       " 'beautiful': 782,\n",
       " 'gotten': 783,\n",
       " 'trip': 784,\n",
       " 'picture': 785,\n",
       " 'due': 786,\n",
       " 'page': 787,\n",
       " 'pictures': 788,\n",
       " '7': 789,\n",
       " 'line': 790,\n",
       " 'party': 791,\n",
       " 'dead': 792,\n",
       " 'giving': 793,\n",
       " 'gives': 794,\n",
       " 'Yes,': 795,\n",
       " 'baby': 796,\n",
       " 'door': 797,\n",
       " 'group': 798,\n",
       " 'strong': 799,\n",
       " 'although': 800,\n",
       " 'mention': 801,\n",
       " 'amazing': 802,\n",
       " 'world.': 803,\n",
       " 'finish': 804,\n",
       " 'fuck': 805,\n",
       " 'perfect': 806,\n",
       " 'sat': 807,\n",
       " 'favorite': 808,\n",
       " 'kill': 809,\n",
       " 'type': 810,\n",
       " 'much.': 811,\n",
       " 'including': 812,\n",
       " 'men': 813,\n",
       " 'friends.': 814,\n",
       " 'anymore.': 815,\n",
       " 'listening': 816,\n",
       " 'relationship': 817,\n",
       " 'Sometimes': 818,\n",
       " \"you've\": 819,\n",
       " 'entire': 820,\n",
       " 'Thank': 821,\n",
       " 'said,': 822,\n",
       " 'boring': 823,\n",
       " 'sad': 824,\n",
       " 'wake': 825,\n",
       " 'Good': 826,\n",
       " \"i'll\": 827,\n",
       " 'young': 828,\n",
       " 'forget': 829,\n",
       " 'managed': 830,\n",
       " 'good,': 831,\n",
       " 'experience': 832,\n",
       " 'asking': 833,\n",
       " 'so,': 834,\n",
       " 'nearly': 835,\n",
       " 'ws': 836,\n",
       " 'happens': 837,\n",
       " 'case': 838,\n",
       " 'leaving': 839,\n",
       " 'knowing': 840,\n",
       " 'place.': 841,\n",
       " 'down.': 842,\n",
       " 'afraid': 843,\n",
       " 'news': 844,\n",
       " 'Bush': 845,\n",
       " 'questions': 846,\n",
       " 'woman': 847,\n",
       " \"we'll\": 848,\n",
       " 'friends,': 849,\n",
       " 'loved': 850,\n",
       " 'school,': 851,\n",
       " 'games': 852,\n",
       " 'simple': 853,\n",
       " 'forgot': 854,\n",
       " 'hang': 855,\n",
       " 'future': 856,\n",
       " 'month': 857,\n",
       " 'mine': 858,\n",
       " 'sweet': 859,\n",
       " 'practice': 860,\n",
       " 'perhaps': 861,\n",
       " 'white': 862,\n",
       " 'ran': 863,\n",
       " 'yeah,': 864,\n",
       " 'one,': 865,\n",
       " 'Have': 866,\n",
       " 'lead': 867,\n",
       " 'me?': 868,\n",
       " 'Are': 869,\n",
       " 'worry': 870,\n",
       " 'say.': 871,\n",
       " 'plan': 872,\n",
       " \"i've\": 873,\n",
       " 'More': 874,\n",
       " 'cold': 875,\n",
       " 'great.': 876,\n",
       " '20': 877,\n",
       " 'company': 878,\n",
       " \"what's\": 879,\n",
       " 'stuck': 880,\n",
       " 'listen': 881,\n",
       " 'it’s': 882,\n",
       " 'driving': 883,\n",
       " 'won': 884,\n",
       " 'deep': 885,\n",
       " 'towards': 886,\n",
       " 'am,': 887,\n",
       " 'begin': 888,\n",
       " 'share': 889,\n",
       " 'major': 890,\n",
       " 'ass': 891,\n",
       " 'dreams': 892,\n",
       " 'then,': 893,\n",
       " 'woke': 894,\n",
       " 'ok': 895,\n",
       " 'boy': 896,\n",
       " 'Michael': 897,\n",
       " 'wonderful': 898,\n",
       " 'Here': 899,\n",
       " 'suppose': 900,\n",
       " 'AND': 901,\n",
       " 'stopped': 902,\n",
       " 'website': 903,\n",
       " 'wrote': 904,\n",
       " 'several': 905,\n",
       " 'large': 906,\n",
       " 'absolutely': 907,\n",
       " 'crap': 908,\n",
       " 'meant': 909,\n",
       " 'better.': 910,\n",
       " 'hopefully': 911,\n",
       " 'While': 912,\n",
       " 'hoping': 913,\n",
       " 'fear': 914,\n",
       " 'thing,': 915,\n",
       " 'link': 916,\n",
       " 'ya': 917,\n",
       " 'Our': 918,\n",
       " 'add': 919,\n",
       " 'war': 920,\n",
       " 'forever': 921,\n",
       " 'complete': 922,\n",
       " '1.': 923,\n",
       " 'mind.': 924,\n",
       " 'week,': 925,\n",
       " 'current': 926,\n",
       " 'back,': 927,\n",
       " 'Nothing': 928,\n",
       " 'control': 929,\n",
       " 'step': 930,\n",
       " 'held': 931,\n",
       " 'answer': 932,\n",
       " 'Now,': 933,\n",
       " 'with.': 934,\n",
       " \"You're\": 935,\n",
       " 'smile': 936,\n",
       " 'cry': 937,\n",
       " 'continue': 938,\n",
       " 'First': 939,\n",
       " 'expect': 940,\n",
       " 'ive': 941,\n",
       " 'home,': 942,\n",
       " 'turns': 943,\n",
       " 'yes,': 944,\n",
       " 'eating': 945,\n",
       " 'fine': 946,\n",
       " 'doubt': 947,\n",
       " 'lose': 948,\n",
       " 'works': 949,\n",
       " 'worked': 950,\n",
       " 'days.': 951,\n",
       " 'These': 952,\n",
       " 'year,': 953,\n",
       " 'starts': 954,\n",
       " 'web': 955,\n",
       " 'speak': 956,\n",
       " 'ill': 957,\n",
       " 'information': 958,\n",
       " 'TO': 959,\n",
       " 'fight': 960,\n",
       " 'done.': 961,\n",
       " 'thank': 962,\n",
       " 'morning.': 963,\n",
       " 'article': 964,\n",
       " 'lol': 965,\n",
       " 'arms': 966,\n",
       " 'kid': 967,\n",
       " 'Where': 968,\n",
       " 'die': 969,\n",
       " 'Go': 970,\n",
       " 'ride': 971,\n",
       " 'near': 972,\n",
       " 'Her': 973,\n",
       " 'weekend.': 974,\n",
       " 'King': 975,\n",
       " 'o': 976,\n",
       " 'trust': 977,\n",
       " 'update': 978,\n",
       " 'college': 979,\n",
       " 'act': 980,\n",
       " 'bored': 981,\n",
       " 'Sunday': 982,\n",
       " 'Friday': 983,\n",
       " 'definitely': 984,\n",
       " 'house.': 985,\n",
       " 'excited': 986,\n",
       " 'noticed': 987,\n",
       " 'liked': 988,\n",
       " '(which': 989,\n",
       " 'Written.': 990,\n",
       " 'fell': 991,\n",
       " 'alot': 992,\n",
       " \"She's\": 993,\n",
       " 'things,': 994,\n",
       " 'Let': 995,\n",
       " 'cut': 996,\n",
       " 'From': 997,\n",
       " 'pass': 998,\n",
       " 'random': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04193627"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('I', 'mine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.063584596"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('ring', 'wife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.018875381"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('ring', 'husband')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09124453"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('woman', 'housewife')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17411754"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('man', 'housewife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.3630428e-03, -3.3598423e-03, -3.5549831e-03,  2.4528505e-04,\n",
       "       -4.7614449e-03,  4.7613895e-03,  4.5550489e-03,  3.8771622e-03,\n",
       "       -3.6376668e-03,  1.4804178e-03, -2.5148613e-03,  1.9925713e-04,\n",
       "        3.5984910e-03,  3.9677023e-05, -3.0117340e-03,  4.5156684e-03,\n",
       "       -4.4915997e-03,  1.1738902e-03, -3.0967165e-03, -4.7881519e-03,\n",
       "        2.5495952e-03, -2.7948045e-03,  9.4641444e-05, -8.7865291e-04,\n",
       "       -8.1568956e-05, -3.4165145e-03,  2.0121546e-03,  4.0507037e-03,\n",
       "       -6.7526104e-05, -1.6083288e-03, -2.2245015e-03, -4.7872807e-03,\n",
       "        2.3600643e-03,  1.7021084e-03, -3.8681501e-03, -1.0601550e-03,\n",
       "       -2.9002053e-03,  2.0705992e-03, -3.2816262e-03,  1.8762333e-03,\n",
       "       -2.8380847e-03,  3.3261932e-03, -1.4033436e-03, -1.2078601e-03,\n",
       "        3.6673206e-03,  1.6874432e-03, -1.5490473e-04,  4.4890614e-03,\n",
       "        3.4259940e-03,  4.0852050e-03, -4.7534453e-03,  6.7709089e-04,\n",
       "       -1.5969985e-03, -2.5910216e-03,  2.5340961e-03,  6.0849666e-04,\n",
       "       -4.6317060e-03, -1.0041404e-03, -1.3085424e-03, -8.3510281e-04,\n",
       "        4.8431782e-03,  4.8770714e-03, -3.2308530e-03, -2.6959837e-03,\n",
       "        3.0843581e-03, -4.7037541e-04,  2.3203921e-03,  2.7410823e-03,\n",
       "        3.7456232e-03,  3.2821209e-03,  4.1624461e-03,  1.0556728e-03,\n",
       "        1.7412931e-03, -1.4119470e-03, -3.4594291e-03,  2.1316123e-03,\n",
       "        1.5169233e-03, -3.0024571e-03, -2.7986455e-03, -1.5437615e-03,\n",
       "       -2.0213502e-03, -2.3067326e-03, -3.7125903e-03,  1.6448325e-03,\n",
       "       -1.0309100e-04,  1.5436762e-03, -1.9314051e-04,  2.2313304e-03,\n",
       "        2.2290975e-03,  4.0241443e-03, -2.7560408e-03, -3.4522135e-03,\n",
       "       -1.8698204e-03, -3.9106067e-03,  2.1108771e-03,  4.7801613e-04,\n",
       "        3.9947508e-03,  2.2375905e-03,  3.4715189e-03, -1.8570685e-03,\n",
       "        2.1525330e-03, -4.6413601e-03,  3.5635538e-03, -8.1491412e-04,\n",
       "        3.1848210e-03, -4.4866544e-03, -4.4257734e-03, -9.1871974e-04,\n",
       "       -2.1583170e-03, -3.8134283e-03,  2.9145593e-03, -1.7594159e-04,\n",
       "       -2.7120591e-04, -2.0271463e-03, -3.2714808e-03, -1.6784859e-03,\n",
       "        4.4920028e-04, -8.0256345e-04, -4.2127925e-03, -3.8132649e-03,\n",
       "       -4.5938422e-03,  2.8314120e-03,  1.9136280e-03,  3.3145798e-03,\n",
       "       -2.8447139e-03,  4.7193561e-03, -4.0283948e-03, -2.8231908e-03,\n",
       "       -7.1418282e-05,  3.3689244e-03, -2.3147035e-03, -3.9049203e-03,\n",
       "       -4.8462409e-03,  1.2104845e-03, -3.1207139e-03, -4.4454038e-03,\n",
       "       -1.4774996e-03, -2.8629543e-04,  4.9059570e-04, -1.9822896e-03,\n",
       "       -5.1792862e-04,  2.6964844e-04,  1.7224163e-03, -9.6408126e-05,\n",
       "        1.0408956e-03,  8.1580936e-04, -2.2119887e-03, -1.6780519e-03,\n",
       "       -4.1729002e-03, -2.0363098e-03,  3.1131930e-03, -4.7559678e-03,\n",
       "       -1.0125935e-04,  1.9951684e-03,  3.7711305e-03,  4.1906987e-03,\n",
       "        1.9727349e-05,  3.1620442e-04, -2.4449169e-03,  1.3792295e-03,\n",
       "        4.2294590e-03,  4.3885428e-03,  4.6540219e-03,  4.5077638e-03,\n",
       "       -3.2931441e-03,  9.3757868e-04,  3.6625534e-03,  2.2687227e-03,\n",
       "       -4.4779666e-03, -6.9971976e-04,  3.6116624e-03,  4.4193538e-03,\n",
       "        1.7206348e-03,  5.3909601e-04,  2.1623135e-04, -8.9758873e-04,\n",
       "        3.9756242e-03, -8.9280726e-04,  1.6954184e-03,  1.0637116e-03,\n",
       "       -3.6168909e-03, -4.8874780e-03,  3.5791396e-05,  4.9446579e-03,\n",
       "       -3.9352542e-03, -3.1197369e-03,  4.6995138e-03,  4.9184979e-04,\n",
       "       -3.5938930e-03, -7.0602598e-04, -3.6543077e-03,  4.0261634e-03,\n",
       "        1.4320862e-03, -1.3382655e-03,  8.1460597e-04,  4.1341884e-03,\n",
       "        2.3588222e-03, -4.4575988e-04, -1.0543395e-03, -1.3834912e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019060344"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('computer', 'keyboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0985767"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('computer', 'mouse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04905799"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('mouse', 'elephant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'breakfast'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use these results in Keras, Embedding layer can be used or input data can be manually transformed into Word2Vec vectors prior to feeding the neural network.\n",
    "\n",
    "## Hands-on ideas\n",
    "\n",
    "* Change the parameters or text above and observe differences.\n",
    "* Check [http://szitnik.github.io/word2vec-tsne/offensive_v2.html](http://szitnik.github.io/word2vec-tsne/offensive_v2.html) to get some ideas of how to use word embeddings. Also, check this repository [https://github.com/UL-FRI-Zitnik/offensive-language-organization](https://github.com/UL-FRI-Zitnik/offensive-language-organization) for further examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further resources\n",
    "\n",
    "* Online book: [http://neuralnetworksanddeeplearning.com/](http://neuralnetworksanddeeplearning.com/)\n",
    "* GitHub repository of iPython notebooks tutorials on Keras & Tensorflow: [https://github.com/leriomaggio/deep-learning-keras-tensorflow](https://github.com/leriomaggio/deep-learning-keras-tensorflow) (parts of them also used in this notebook)\n",
    "* Google Codelabs tutorial: [https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0)\n",
    "* Tensorflow tutorial: [https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/)\n",
    "* Andrew Ng's Machine Learning Coursera course: [https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
